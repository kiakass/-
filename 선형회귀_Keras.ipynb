{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "선형회귀_Keras.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNBO9uRKN13E18oOb7HKo9I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiakass/tensorflow/blob/master/%EC%84%A0%ED%98%95%ED%9A%8C%EA%B7%80_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVMMa4R0hI7-"
      },
      "source": [
        "# package, module 를 import\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from tensorflow import keras\n",
        "\n",
        "#from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.utils import np_utils\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "#data\n",
        "from sklearn.datasets import fetch_california_housing"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx20uqHghy3S",
        "outputId": "3044b41a-f623-4fa9-fd95-6ebea047bb9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "df = fetch_california_housing()\n",
        "X1 = pd.DataFrame(df.data, columns=df.feature_names)\n",
        "X2 = pd.DataFrame(df.target, columns=['Sales'])\n",
        "housing=pd.concat([X1,X2], axis=1) #.drop(['Education'], axis=1)\n",
        "housing"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8.3252</td>\n",
              "      <td>41.0</td>\n",
              "      <td>6.984127</td>\n",
              "      <td>1.023810</td>\n",
              "      <td>322.0</td>\n",
              "      <td>2.555556</td>\n",
              "      <td>37.88</td>\n",
              "      <td>-122.23</td>\n",
              "      <td>4.526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8.3014</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6.238137</td>\n",
              "      <td>0.971880</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>2.109842</td>\n",
              "      <td>37.86</td>\n",
              "      <td>-122.22</td>\n",
              "      <td>3.585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.2574</td>\n",
              "      <td>52.0</td>\n",
              "      <td>8.288136</td>\n",
              "      <td>1.073446</td>\n",
              "      <td>496.0</td>\n",
              "      <td>2.802260</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.24</td>\n",
              "      <td>3.521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.6431</td>\n",
              "      <td>52.0</td>\n",
              "      <td>5.817352</td>\n",
              "      <td>1.073059</td>\n",
              "      <td>558.0</td>\n",
              "      <td>2.547945</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "      <td>3.413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.8462</td>\n",
              "      <td>52.0</td>\n",
              "      <td>6.281853</td>\n",
              "      <td>1.081081</td>\n",
              "      <td>565.0</td>\n",
              "      <td>2.181467</td>\n",
              "      <td>37.85</td>\n",
              "      <td>-122.25</td>\n",
              "      <td>3.422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>1.5603</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.045455</td>\n",
              "      <td>1.133333</td>\n",
              "      <td>845.0</td>\n",
              "      <td>2.560606</td>\n",
              "      <td>39.48</td>\n",
              "      <td>-121.09</td>\n",
              "      <td>0.781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>2.5568</td>\n",
              "      <td>18.0</td>\n",
              "      <td>6.114035</td>\n",
              "      <td>1.315789</td>\n",
              "      <td>356.0</td>\n",
              "      <td>3.122807</td>\n",
              "      <td>39.49</td>\n",
              "      <td>-121.21</td>\n",
              "      <td>0.771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>1.7000</td>\n",
              "      <td>17.0</td>\n",
              "      <td>5.205543</td>\n",
              "      <td>1.120092</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>2.325635</td>\n",
              "      <td>39.43</td>\n",
              "      <td>-121.22</td>\n",
              "      <td>0.923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>1.8672</td>\n",
              "      <td>18.0</td>\n",
              "      <td>5.329513</td>\n",
              "      <td>1.171920</td>\n",
              "      <td>741.0</td>\n",
              "      <td>2.123209</td>\n",
              "      <td>39.43</td>\n",
              "      <td>-121.32</td>\n",
              "      <td>0.847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>2.3886</td>\n",
              "      <td>16.0</td>\n",
              "      <td>5.254717</td>\n",
              "      <td>1.162264</td>\n",
              "      <td>1387.0</td>\n",
              "      <td>2.616981</td>\n",
              "      <td>39.37</td>\n",
              "      <td>-121.24</td>\n",
              "      <td>0.894</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       MedInc  HouseAge  AveRooms  ...  Latitude  Longitude  Sales\n",
              "0      8.3252      41.0  6.984127  ...     37.88    -122.23  4.526\n",
              "1      8.3014      21.0  6.238137  ...     37.86    -122.22  3.585\n",
              "2      7.2574      52.0  8.288136  ...     37.85    -122.24  3.521\n",
              "3      5.6431      52.0  5.817352  ...     37.85    -122.25  3.413\n",
              "4      3.8462      52.0  6.281853  ...     37.85    -122.25  3.422\n",
              "...       ...       ...       ...  ...       ...        ...    ...\n",
              "20635  1.5603      25.0  5.045455  ...     39.48    -121.09  0.781\n",
              "20636  2.5568      18.0  6.114035  ...     39.49    -121.21  0.771\n",
              "20637  1.7000      17.0  5.205543  ...     39.43    -121.22  0.923\n",
              "20638  1.8672      18.0  5.329513  ...     39.43    -121.32  0.847\n",
              "20639  2.3886      16.0  5.254717  ...     39.37    -121.24  0.894\n",
              "\n",
              "[20640 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jHNFBtliOK5"
      },
      "source": [
        "# 훈련/검증용 데이터 분리\n",
        "from sklearn.model_selection import train_test_split \n",
        "X = housing.iloc[:, 0:4]\n",
        "y = housing.iloc[:, 8]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWi3kKibiT9w"
      },
      "source": [
        "# 3. 훈련/검증용 데이터 분할\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3, random_state=1 )"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "des20wmLhKrI",
        "outputId": "ac87e9ec-abe9-4388-9df6-f543db2d389a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "rmsprop = RMSprop(lr=0.01)\n",
        "model = Sequential()\n",
        "model.add(Dense(1,input_dim=4))\n",
        "\n",
        "#model compile\n",
        "model.compile(loss='mse', optimizer='adam') # adam , rmsprop\n",
        "model.summary()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 1)                 5         \n",
            "=================================================================\n",
            "Total params: 5\n",
            "Trainable params: 5\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v488WwVwhQ4w",
        "outputId": "a4fe52a1-94b4-4977-aeac-32522fd100e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = 1000\n",
        "epochs = 1000\n",
        "\n",
        "\n",
        "# Early Stop : patience #n 회 이상 val_loss 가 변화가 없으면 중단\n",
        "es = EarlyStopping(monitor='val_loss', patience=20, min_delta=0.001)\n",
        "\n",
        "# model fit\n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_train, Y_train),\n",
        "                    callbacks=[es]) #validation_split=0.2 "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "15/15 [==============================] - 0s 10ms/step - loss: 242.5984 - val_loss: 232.1575\n",
            "Epoch 2/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 223.8350 - val_loss: 213.9341\n",
            "Epoch 3/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 206.1489 - val_loss: 196.7474\n",
            "Epoch 4/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 189.4727 - val_loss: 180.7185\n",
            "Epoch 5/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 173.9474 - val_loss: 165.7216\n",
            "Epoch 6/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 159.3725 - val_loss: 151.7984\n",
            "Epoch 7/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 145.8881 - val_loss: 138.7534\n",
            "Epoch 8/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 133.2368 - val_loss: 126.7191\n",
            "Epoch 9/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 121.6057 - val_loss: 115.4514\n",
            "Epoch 10/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 110.7188 - val_loss: 105.1226\n",
            "Epoch 11/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 100.7413 - val_loss: 95.5305\n",
            "Epoch 12/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 91.5332 - val_loss: 86.7322\n",
            "Epoch 13/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 83.0766 - val_loss: 78.6549\n",
            "Epoch 14/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 75.3136 - val_loss: 71.2639\n",
            "Epoch 15/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 68.1823 - val_loss: 64.5337\n",
            "Epoch 16/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 61.7081 - val_loss: 58.3730\n",
            "Epoch 17/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 55.8031 - val_loss: 52.7600\n",
            "Epoch 18/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 50.4372 - val_loss: 47.6633\n",
            "Epoch 19/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 45.5602 - val_loss: 43.0684\n",
            "Epoch 20/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 41.1617 - val_loss: 38.9240\n",
            "Epoch 21/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 37.1970 - val_loss: 35.1882\n",
            "Epoch 22/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 33.6406 - val_loss: 31.7844\n",
            "Epoch 23/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 30.4143 - val_loss: 28.7891\n",
            "Epoch 24/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 27.5715 - val_loss: 26.1107\n",
            "Epoch 25/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 25.0246 - val_loss: 23.7420\n",
            "Epoch 26/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 22.7751 - val_loss: 21.6356\n",
            "Epoch 27/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 20.7842 - val_loss: 19.7563\n",
            "Epoch 28/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 19.0088 - val_loss: 18.1052\n",
            "Epoch 29/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 17.4455 - val_loss: 16.6653\n",
            "Epoch 30/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 16.0861 - val_loss: 15.3952\n",
            "Epoch 31/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 14.8840 - val_loss: 14.2856\n",
            "Epoch 32/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 13.8386 - val_loss: 13.3129\n",
            "Epoch 33/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 12.9216 - val_loss: 12.4716\n",
            "Epoch 34/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 12.1304 - val_loss: 11.7349\n",
            "Epoch 35/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 11.4429 - val_loss: 11.0968\n",
            "Epoch 36/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 10.8440 - val_loss: 10.5513\n",
            "Epoch 37/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 10.3349 - val_loss: 10.0764\n",
            "Epoch 38/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.8915 - val_loss: 9.6698\n",
            "Epoch 39/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.5085 - val_loss: 9.3242\n",
            "Epoch 40/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 9.1792 - val_loss: 9.0167\n",
            "Epoch 41/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.8949 - val_loss: 8.7572\n",
            "Epoch 42/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.6570 - val_loss: 8.5323\n",
            "Epoch 43/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 8.4477 - val_loss: 8.3429\n",
            "Epoch 44/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.2660 - val_loss: 8.1855\n",
            "Epoch 45/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 8.1138 - val_loss: 8.0339\n",
            "Epoch 46/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.9765 - val_loss: 7.9106\n",
            "Epoch 47/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.8630 - val_loss: 7.8029\n",
            "Epoch 48/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.7605 - val_loss: 7.7134\n",
            "Epoch 49/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.6769 - val_loss: 7.6306\n",
            "Epoch 50/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.5971 - val_loss: 7.5604\n",
            "Epoch 51/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.5311 - val_loss: 7.4936\n",
            "Epoch 52/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.4673 - val_loss: 7.4348\n",
            "Epoch 53/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.4108 - val_loss: 7.3813\n",
            "Epoch 54/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.3599 - val_loss: 7.3309\n",
            "Epoch 55/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.3097 - val_loss: 7.2867\n",
            "Epoch 56/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.2654 - val_loss: 7.2427\n",
            "Epoch 57/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.2235 - val_loss: 7.1992\n",
            "Epoch 58/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.1811 - val_loss: 7.1588\n",
            "Epoch 59/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.1418 - val_loss: 7.1192\n",
            "Epoch 60/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 7.1030 - val_loss: 7.0817\n",
            "Epoch 61/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.0655 - val_loss: 7.0460\n",
            "Epoch 62/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 7.0299 - val_loss: 7.0088\n",
            "Epoch 63/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.9930 - val_loss: 6.9735\n",
            "Epoch 64/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.9570 - val_loss: 6.9377\n",
            "Epoch 65/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.9231 - val_loss: 6.8980\n",
            "Epoch 66/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.8824 - val_loss: 6.8642\n",
            "Epoch 67/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.8480 - val_loss: 6.8290\n",
            "Epoch 68/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.8128 - val_loss: 6.7942\n",
            "Epoch 69/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.7790 - val_loss: 6.7574\n",
            "Epoch 70/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.7422 - val_loss: 6.7231\n",
            "Epoch 71/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.7066 - val_loss: 6.6883\n",
            "Epoch 72/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.6725 - val_loss: 6.6514\n",
            "Epoch 73/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.6359 - val_loss: 6.6163\n",
            "Epoch 74/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.6002 - val_loss: 6.5804\n",
            "Epoch 75/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.5650 - val_loss: 6.5438\n",
            "Epoch 76/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.5287 - val_loss: 6.5082\n",
            "Epoch 77/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.4931 - val_loss: 6.4721\n",
            "Epoch 78/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.4571 - val_loss: 6.4360\n",
            "Epoch 79/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.4205 - val_loss: 6.4011\n",
            "Epoch 80/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.3849 - val_loss: 6.3651\n",
            "Epoch 81/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.3493 - val_loss: 6.3285\n",
            "Epoch 82/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.3143 - val_loss: 6.2907\n",
            "Epoch 83/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.2749 - val_loss: 6.2561\n",
            "Epoch 84/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.2410 - val_loss: 6.2177\n",
            "Epoch 85/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.2021 - val_loss: 6.1817\n",
            "Epoch 86/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.1649 - val_loss: 6.1456\n",
            "Epoch 87/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.1264 - val_loss: 6.1067\n",
            "Epoch 88/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.0893 - val_loss: 6.0690\n",
            "Epoch 89/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 6.0525 - val_loss: 6.0307\n",
            "Epoch 90/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 6.0153 - val_loss: 5.9933\n",
            "Epoch 91/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.9774 - val_loss: 5.9568\n",
            "Epoch 92/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.9401 - val_loss: 5.9198\n",
            "Epoch 93/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.9052 - val_loss: 5.8809\n",
            "Epoch 94/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.8654 - val_loss: 5.8453\n",
            "Epoch 95/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.8287 - val_loss: 5.8079\n",
            "Epoch 96/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.7916 - val_loss: 5.7703\n",
            "Epoch 97/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.7534 - val_loss: 5.7346\n",
            "Epoch 98/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.7167 - val_loss: 5.6966\n",
            "Epoch 99/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.6781 - val_loss: 5.6586\n",
            "Epoch 100/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.6409 - val_loss: 5.6193\n",
            "Epoch 101/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.6023 - val_loss: 5.5813\n",
            "Epoch 102/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.5651 - val_loss: 5.5425\n",
            "Epoch 103/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.5262 - val_loss: 5.5053\n",
            "Epoch 104/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.4892 - val_loss: 5.4674\n",
            "Epoch 105/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.4513 - val_loss: 5.4298\n",
            "Epoch 106/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.4133 - val_loss: 5.3914\n",
            "Epoch 107/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3754 - val_loss: 5.3531\n",
            "Epoch 108/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.3370 - val_loss: 5.3156\n",
            "Epoch 109/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2994 - val_loss: 5.2777\n",
            "Epoch 110/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 5.2610 - val_loss: 5.2409\n",
            "Epoch 111/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.2243 - val_loss: 5.2027\n",
            "Epoch 112/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1868 - val_loss: 5.1645\n",
            "Epoch 113/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1495 - val_loss: 5.1264\n",
            "Epoch 114/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.1101 - val_loss: 5.0911\n",
            "Epoch 115/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.0737 - val_loss: 5.0534\n",
            "Epoch 116/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 5.0369 - val_loss: 5.0149\n",
            "Epoch 117/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.9979 - val_loss: 4.9795\n",
            "Epoch 118/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.9611 - val_loss: 4.9374\n",
            "Epoch 119/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.9194 - val_loss: 4.9002\n",
            "Epoch 120/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8827 - val_loss: 4.8617\n",
            "Epoch 121/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8417 - val_loss: 4.8228\n",
            "Epoch 122/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.8043 - val_loss: 4.7842\n",
            "Epoch 123/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7674 - val_loss: 4.7460\n",
            "Epoch 124/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.7308 - val_loss: 4.7075\n",
            "Epoch 125/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.6938 - val_loss: 4.6696\n",
            "Epoch 126/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.6546 - val_loss: 4.6342\n",
            "Epoch 127/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.6179 - val_loss: 4.5979\n",
            "Epoch 128/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.5819 - val_loss: 4.5611\n",
            "Epoch 129/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.5465 - val_loss: 4.5226\n",
            "Epoch 130/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.5079 - val_loss: 4.4862\n",
            "Epoch 131/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.4705 - val_loss: 4.4497\n",
            "Epoch 132/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.4337 - val_loss: 4.4137\n",
            "Epoch 133/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.3972 - val_loss: 4.3777\n",
            "Epoch 134/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.3609 - val_loss: 4.3418\n",
            "Epoch 135/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.3263 - val_loss: 4.3035\n",
            "Epoch 136/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.2887 - val_loss: 4.2668\n",
            "Epoch 137/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.2512 - val_loss: 4.2322\n",
            "Epoch 138/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.2159 - val_loss: 4.1962\n",
            "Epoch 139/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.1814 - val_loss: 4.1587\n",
            "Epoch 140/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.1434 - val_loss: 4.1233\n",
            "Epoch 141/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 4.1079 - val_loss: 4.0886\n",
            "Epoch 142/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.0733 - val_loss: 4.0517\n",
            "Epoch 143/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.0361 - val_loss: 4.0183\n",
            "Epoch 144/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 4.0021 - val_loss: 3.9774\n",
            "Epoch 145/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.9637 - val_loss: 3.9412\n",
            "Epoch 146/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.9273 - val_loss: 3.9061\n",
            "Epoch 147/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.8906 - val_loss: 3.8733\n",
            "Epoch 148/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.8573 - val_loss: 3.8379\n",
            "Epoch 149/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.8216 - val_loss: 3.8048\n",
            "Epoch 150/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7884 - val_loss: 3.7688\n",
            "Epoch 151/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7532 - val_loss: 3.7345\n",
            "Epoch 152/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.7185 - val_loss: 3.7007\n",
            "Epoch 153/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.6852 - val_loss: 3.6657\n",
            "Epoch 154/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.6503 - val_loss: 3.6318\n",
            "Epoch 155/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.6161 - val_loss: 3.5972\n",
            "Epoch 156/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.5835 - val_loss: 3.5621\n",
            "Epoch 157/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.5472 - val_loss: 3.5303\n",
            "Epoch 158/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.5123 - val_loss: 3.4944\n",
            "Epoch 159/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4795 - val_loss: 3.4588\n",
            "Epoch 160/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.4441 - val_loss: 3.4265\n",
            "Epoch 161/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.4122 - val_loss: 3.3928\n",
            "Epoch 162/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.3783 - val_loss: 3.3612\n",
            "Epoch 163/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.3471 - val_loss: 3.3279\n",
            "Epoch 164/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.3135 - val_loss: 3.2965\n",
            "Epoch 165/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.2820 - val_loss: 3.2639\n",
            "Epoch 166/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.2489 - val_loss: 3.2323\n",
            "Epoch 167/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.2179 - val_loss: 3.2001\n",
            "Epoch 168/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.1857 - val_loss: 3.1685\n",
            "Epoch 169/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.1543 - val_loss: 3.1369\n",
            "Epoch 170/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.1224 - val_loss: 3.1054\n",
            "Epoch 171/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.0910 - val_loss: 3.0725\n",
            "Epoch 172/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 3.0599 - val_loss: 3.0405\n",
            "Epoch 173/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 3.0269 - val_loss: 3.0112\n",
            "Epoch 174/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9973 - val_loss: 2.9760\n",
            "Epoch 175/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9621 - val_loss: 2.9476\n",
            "Epoch 176/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.9353 - val_loss: 2.9115\n",
            "Epoch 177/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.8984 - val_loss: 2.8835\n",
            "Epoch 178/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.8690 - val_loss: 2.8541\n",
            "Epoch 179/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.8422 - val_loss: 2.8219\n",
            "Epoch 180/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.8092 - val_loss: 2.7949\n",
            "Epoch 181/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7829 - val_loss: 2.7637\n",
            "Epoch 182/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.7513 - val_loss: 2.7355\n",
            "Epoch 183/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.7246 - val_loss: 2.7055\n",
            "Epoch 184/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.6937 - val_loss: 2.6779\n",
            "Epoch 185/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.6650 - val_loss: 2.6516\n",
            "Epoch 186/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.6378 - val_loss: 2.6188\n",
            "Epoch 187/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.6052 - val_loss: 2.5923\n",
            "Epoch 188/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.5776 - val_loss: 2.5606\n",
            "Epoch 189/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.5476 - val_loss: 2.5324\n",
            "Epoch 190/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.5196 - val_loss: 2.5054\n",
            "Epoch 191/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.4934 - val_loss: 2.4775\n",
            "Epoch 192/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.4665 - val_loss: 2.4503\n",
            "Epoch 193/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4386 - val_loss: 2.4246\n",
            "Epoch 194/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.4127 - val_loss: 2.3977\n",
            "Epoch 195/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3854 - val_loss: 2.3716\n",
            "Epoch 196/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.3603 - val_loss: 2.3447\n",
            "Epoch 197/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3331 - val_loss: 2.3199\n",
            "Epoch 198/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.3097 - val_loss: 2.2932\n",
            "Epoch 199/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2821 - val_loss: 2.2699\n",
            "Epoch 200/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2582 - val_loss: 2.2446\n",
            "Epoch 201/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.2328 - val_loss: 2.2204\n",
            "Epoch 202/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.2094 - val_loss: 2.1948\n",
            "Epoch 203/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.1851 - val_loss: 2.1693\n",
            "Epoch 204/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.1592 - val_loss: 2.1460\n",
            "Epoch 205/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.1367 - val_loss: 2.1214\n",
            "Epoch 206/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.1117 - val_loss: 2.0984\n",
            "Epoch 207/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.0886 - val_loss: 2.0757\n",
            "Epoch 208/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.0663 - val_loss: 2.0514\n",
            "Epoch 209/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 2.0421 - val_loss: 2.0286\n",
            "Epoch 210/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 2.0191 - val_loss: 2.0064\n",
            "Epoch 211/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.9978 - val_loss: 1.9834\n",
            "Epoch 212/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.9749 - val_loss: 1.9610\n",
            "Epoch 213/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.9527 - val_loss: 1.9390\n",
            "Epoch 214/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.9296 - val_loss: 1.9189\n",
            "Epoch 215/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.9090 - val_loss: 1.8972\n",
            "Epoch 216/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8876 - val_loss: 1.8758\n",
            "Epoch 217/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8667 - val_loss: 1.8544\n",
            "Epoch 218/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8457 - val_loss: 1.8335\n",
            "Epoch 219/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.8246 - val_loss: 1.8133\n",
            "Epoch 220/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.8048 - val_loss: 1.7924\n",
            "Epoch 221/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.7835 - val_loss: 1.7732\n",
            "Epoch 222/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.7643 - val_loss: 1.7530\n",
            "Epoch 223/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7444 - val_loss: 1.7335\n",
            "Epoch 224/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.7252 - val_loss: 1.7138\n",
            "Epoch 225/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.7061 - val_loss: 1.6942\n",
            "Epoch 226/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.6864 - val_loss: 1.6749\n",
            "Epoch 227/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.6670 - val_loss: 1.6567\n",
            "Epoch 228/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.6492 - val_loss: 1.6380\n",
            "Epoch 229/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.6304 - val_loss: 1.6199\n",
            "Epoch 230/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.6120 - val_loss: 1.6025\n",
            "Epoch 231/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5946 - val_loss: 1.5844\n",
            "Epoch 232/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5768 - val_loss: 1.5665\n",
            "Epoch 233/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5587 - val_loss: 1.5495\n",
            "Epoch 234/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5418 - val_loss: 1.5323\n",
            "Epoch 235/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5242 - val_loss: 1.5160\n",
            "Epoch 236/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.5078 - val_loss: 1.4966\n",
            "Epoch 237/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4893 - val_loss: 1.4799\n",
            "Epoch 238/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4737 - val_loss: 1.4629\n",
            "Epoch 239/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4558 - val_loss: 1.4481\n",
            "Epoch 240/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4404 - val_loss: 1.4300\n",
            "Epoch 241/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.4232 - val_loss: 1.4140\n",
            "Epoch 242/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.4076 - val_loss: 1.3985\n",
            "Epoch 243/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.3918 - val_loss: 1.3841\n",
            "Epoch 244/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.3769 - val_loss: 1.3698\n",
            "Epoch 245/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3613 - val_loss: 1.3536\n",
            "Epoch 246/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3464 - val_loss: 1.3367\n",
            "Epoch 247/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.3301 - val_loss: 1.3225\n",
            "Epoch 248/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.3167 - val_loss: 1.3080\n",
            "Epoch 249/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.3021 - val_loss: 1.2945\n",
            "Epoch 250/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2890 - val_loss: 1.2808\n",
            "Epoch 251/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2752 - val_loss: 1.2677\n",
            "Epoch 252/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.2623 - val_loss: 1.2544\n",
            "Epoch 253/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2490 - val_loss: 1.2418\n",
            "Epoch 254/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2362 - val_loss: 1.2294\n",
            "Epoch 255/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2244 - val_loss: 1.2161\n",
            "Epoch 256/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.2110 - val_loss: 1.2040\n",
            "Epoch 257/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1989 - val_loss: 1.1918\n",
            "Epoch 258/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1868 - val_loss: 1.1801\n",
            "Epoch 259/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1747 - val_loss: 1.1688\n",
            "Epoch 260/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1631 - val_loss: 1.1557\n",
            "Epoch 261/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1506 - val_loss: 1.1442\n",
            "Epoch 262/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1390 - val_loss: 1.1338\n",
            "Epoch 263/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1280 - val_loss: 1.1212\n",
            "Epoch 264/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.1163 - val_loss: 1.1105\n",
            "Epoch 265/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.1049 - val_loss: 1.0991\n",
            "Epoch 266/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0942 - val_loss: 1.0886\n",
            "Epoch 267/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0838 - val_loss: 1.0786\n",
            "Epoch 268/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0732 - val_loss: 1.0677\n",
            "Epoch 269/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0631 - val_loss: 1.0576\n",
            "Epoch 270/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0531 - val_loss: 1.0485\n",
            "Epoch 271/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0443 - val_loss: 1.0386\n",
            "Epoch 272/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 1.0346 - val_loss: 1.0295\n",
            "Epoch 273/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0255 - val_loss: 1.0207\n",
            "Epoch 274/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0169 - val_loss: 1.0114\n",
            "Epoch 275/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 1.0077 - val_loss: 1.0030\n",
            "Epoch 276/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9994 - val_loss: 0.9945\n",
            "Epoch 277/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9913 - val_loss: 0.9860\n",
            "Epoch 278/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9828 - val_loss: 0.9780\n",
            "Epoch 279/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9748 - val_loss: 0.9699\n",
            "Epoch 280/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.9666 - val_loss: 0.9625\n",
            "Epoch 281/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.9592 - val_loss: 0.9549\n",
            "Epoch 282/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.9517 - val_loss: 0.9473\n",
            "Epoch 283/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9442 - val_loss: 0.9402\n",
            "Epoch 284/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.9370 - val_loss: 0.9332\n",
            "Epoch 285/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.9301 - val_loss: 0.9261\n",
            "Epoch 286/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9232 - val_loss: 0.9192\n",
            "Epoch 287/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9162 - val_loss: 0.9127\n",
            "Epoch 288/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9098 - val_loss: 0.9059\n",
            "Epoch 289/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.9032 - val_loss: 0.8994\n",
            "Epoch 290/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8966 - val_loss: 0.8934\n",
            "Epoch 291/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8905 - val_loss: 0.8873\n",
            "Epoch 292/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8849 - val_loss: 0.8810\n",
            "Epoch 293/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8785 - val_loss: 0.8753\n",
            "Epoch 294/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8729 - val_loss: 0.8695\n",
            "Epoch 295/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8670 - val_loss: 0.8641\n",
            "Epoch 296/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8616 - val_loss: 0.8585\n",
            "Epoch 297/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8562 - val_loss: 0.8531\n",
            "Epoch 298/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8509 - val_loss: 0.8479\n",
            "Epoch 299/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8456 - val_loss: 0.8430\n",
            "Epoch 300/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8408 - val_loss: 0.8372\n",
            "Epoch 301/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8352 - val_loss: 0.8325\n",
            "Epoch 302/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8304 - val_loss: 0.8279\n",
            "Epoch 303/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8259 - val_loss: 0.8232\n",
            "Epoch 304/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8213 - val_loss: 0.8189\n",
            "Epoch 305/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8169 - val_loss: 0.8146\n",
            "Epoch 306/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8126 - val_loss: 0.8098\n",
            "Epoch 307/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8080 - val_loss: 0.8057\n",
            "Epoch 308/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.8039 - val_loss: 0.8016\n",
            "Epoch 309/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.8001 - val_loss: 0.7975\n",
            "Epoch 310/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7959 - val_loss: 0.7940\n",
            "Epoch 311/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7924 - val_loss: 0.7902\n",
            "Epoch 312/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7888 - val_loss: 0.7866\n",
            "Epoch 313/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7851 - val_loss: 0.7832\n",
            "Epoch 314/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7817 - val_loss: 0.7797\n",
            "Epoch 315/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7783 - val_loss: 0.7765\n",
            "Epoch 316/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7751 - val_loss: 0.7732\n",
            "Epoch 317/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7719 - val_loss: 0.7701\n",
            "Epoch 318/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7687 - val_loss: 0.7671\n",
            "Epoch 319/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7657 - val_loss: 0.7641\n",
            "Epoch 320/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7628 - val_loss: 0.7611\n",
            "Epoch 321/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7600 - val_loss: 0.7583\n",
            "Epoch 322/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7572 - val_loss: 0.7556\n",
            "Epoch 323/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7544 - val_loss: 0.7531\n",
            "Epoch 324/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7519 - val_loss: 0.7504\n",
            "Epoch 325/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7493 - val_loss: 0.7481\n",
            "Epoch 326/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7470 - val_loss: 0.7456\n",
            "Epoch 327/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7444 - val_loss: 0.7430\n",
            "Epoch 328/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7419 - val_loss: 0.7409\n",
            "Epoch 329/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7399 - val_loss: 0.7386\n",
            "Epoch 330/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7376 - val_loss: 0.7364\n",
            "Epoch 331/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7354 - val_loss: 0.7344\n",
            "Epoch 332/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7335 - val_loss: 0.7322\n",
            "Epoch 333/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7313 - val_loss: 0.7303\n",
            "Epoch 334/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7294 - val_loss: 0.7284\n",
            "Epoch 335/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7277 - val_loss: 0.7266\n",
            "Epoch 336/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7258 - val_loss: 0.7248\n",
            "Epoch 337/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7241 - val_loss: 0.7231\n",
            "Epoch 338/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7224 - val_loss: 0.7215\n",
            "Epoch 339/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7208 - val_loss: 0.7200\n",
            "Epoch 340/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7193 - val_loss: 0.7184\n",
            "Epoch 341/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7177 - val_loss: 0.7169\n",
            "Epoch 342/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7163 - val_loss: 0.7155\n",
            "Epoch 343/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7149 - val_loss: 0.7142\n",
            "Epoch 344/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7135 - val_loss: 0.7127\n",
            "Epoch 345/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7121 - val_loss: 0.7114\n",
            "Epoch 346/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7109 - val_loss: 0.7101\n",
            "Epoch 347/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7096 - val_loss: 0.7089\n",
            "Epoch 348/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7084 - val_loss: 0.7078\n",
            "Epoch 349/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7073 - val_loss: 0.7066\n",
            "Epoch 350/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7062 - val_loss: 0.7055\n",
            "Epoch 351/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7051 - val_loss: 0.7045\n",
            "Epoch 352/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7041 - val_loss: 0.7035\n",
            "Epoch 353/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7031 - val_loss: 0.7025\n",
            "Epoch 354/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7021 - val_loss: 0.7015\n",
            "Epoch 355/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.7012 - val_loss: 0.7006\n",
            "Epoch 356/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.7003 - val_loss: 0.6998\n",
            "Epoch 357/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6994 - val_loss: 0.6989\n",
            "Epoch 358/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6985 - val_loss: 0.6981\n",
            "Epoch 359/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6977 - val_loss: 0.6973\n",
            "Epoch 360/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6970 - val_loss: 0.6965\n",
            "Epoch 361/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6962 - val_loss: 0.6958\n",
            "Epoch 362/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6955 - val_loss: 0.6951\n",
            "Epoch 363/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6947 - val_loss: 0.6944\n",
            "Epoch 364/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6941 - val_loss: 0.6937\n",
            "Epoch 365/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6934 - val_loss: 0.6930\n",
            "Epoch 366/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6927 - val_loss: 0.6924\n",
            "Epoch 367/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6921 - val_loss: 0.6917\n",
            "Epoch 368/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6915 - val_loss: 0.6912\n",
            "Epoch 369/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6909 - val_loss: 0.6906\n",
            "Epoch 370/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6904 - val_loss: 0.6900\n",
            "Epoch 371/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6898 - val_loss: 0.6895\n",
            "Epoch 372/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6894 - val_loss: 0.6890\n",
            "Epoch 373/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6888 - val_loss: 0.6885\n",
            "Epoch 374/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6883 - val_loss: 0.6880\n",
            "Epoch 375/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6878 - val_loss: 0.6876\n",
            "Epoch 376/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6874 - val_loss: 0.6871\n",
            "Epoch 377/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6869 - val_loss: 0.6867\n",
            "Epoch 378/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6865 - val_loss: 0.6862\n",
            "Epoch 379/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6861 - val_loss: 0.6858\n",
            "Epoch 380/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6857 - val_loss: 0.6854\n",
            "Epoch 381/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6852 - val_loss: 0.6850\n",
            "Epoch 382/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6849 - val_loss: 0.6847\n",
            "Epoch 383/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6846 - val_loss: 0.6843\n",
            "Epoch 384/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6841 - val_loss: 0.6839\n",
            "Epoch 385/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6838 - val_loss: 0.6836\n",
            "Epoch 386/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6835 - val_loss: 0.6832\n",
            "Epoch 387/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6831 - val_loss: 0.6829\n",
            "Epoch 388/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6828 - val_loss: 0.6826\n",
            "Epoch 389/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6825 - val_loss: 0.6823\n",
            "Epoch 390/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6821 - val_loss: 0.6820\n",
            "Epoch 391/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6819 - val_loss: 0.6817\n",
            "Epoch 392/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6816 - val_loss: 0.6814\n",
            "Epoch 393/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6813 - val_loss: 0.6811\n",
            "Epoch 394/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6810 - val_loss: 0.6808\n",
            "Epoch 395/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6808 - val_loss: 0.6805\n",
            "Epoch 396/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6805 - val_loss: 0.6803\n",
            "Epoch 397/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6802 - val_loss: 0.6800\n",
            "Epoch 398/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6799 - val_loss: 0.6797\n",
            "Epoch 399/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6797 - val_loss: 0.6795\n",
            "Epoch 400/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6794 - val_loss: 0.6792\n",
            "Epoch 401/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6791 - val_loss: 0.6790\n",
            "Epoch 402/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6790 - val_loss: 0.6788\n",
            "Epoch 403/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6787 - val_loss: 0.6786\n",
            "Epoch 404/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6784 - val_loss: 0.6783\n",
            "Epoch 405/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6782 - val_loss: 0.6780\n",
            "Epoch 406/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6780 - val_loss: 0.6778\n",
            "Epoch 407/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6778 - val_loss: 0.6776\n",
            "Epoch 408/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6775 - val_loss: 0.6774\n",
            "Epoch 409/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6773 - val_loss: 0.6772\n",
            "Epoch 410/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6771 - val_loss: 0.6769\n",
            "Epoch 411/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6769 - val_loss: 0.6767\n",
            "Epoch 412/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6767 - val_loss: 0.6765\n",
            "Epoch 413/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6764 - val_loss: 0.6763\n",
            "Epoch 414/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6762 - val_loss: 0.6761\n",
            "Epoch 415/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6761 - val_loss: 0.6759\n",
            "Epoch 416/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6758 - val_loss: 0.6756\n",
            "Epoch 417/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6756 - val_loss: 0.6754\n",
            "Epoch 418/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6754 - val_loss: 0.6752\n",
            "Epoch 419/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6751 - val_loss: 0.6750\n",
            "Epoch 420/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6749 - val_loss: 0.6748\n",
            "Epoch 421/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6747 - val_loss: 0.6746\n",
            "Epoch 422/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6745 - val_loss: 0.6744\n",
            "Epoch 423/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6743 - val_loss: 0.6742\n",
            "Epoch 424/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6741 - val_loss: 0.6740\n",
            "Epoch 425/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6739 - val_loss: 0.6738\n",
            "Epoch 426/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6738 - val_loss: 0.6736\n",
            "Epoch 427/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6735 - val_loss: 0.6734\n",
            "Epoch 428/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6733 - val_loss: 0.6732\n",
            "Epoch 429/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6731 - val_loss: 0.6730\n",
            "Epoch 430/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6729 - val_loss: 0.6728\n",
            "Epoch 431/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.6726\n",
            "Epoch 432/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.6724\n",
            "Epoch 433/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6724 - val_loss: 0.6722\n",
            "Epoch 434/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6722 - val_loss: 0.6720\n",
            "Epoch 435/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6720 - val_loss: 0.6718\n",
            "Epoch 436/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6717 - val_loss: 0.6716\n",
            "Epoch 437/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6716 - val_loss: 0.6714\n",
            "Epoch 438/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6714 - val_loss: 0.6713\n",
            "Epoch 439/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6713 - val_loss: 0.6710\n",
            "Epoch 440/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6709 - val_loss: 0.6708\n",
            "Epoch 441/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6708 - val_loss: 0.6706\n",
            "Epoch 442/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6706 - val_loss: 0.6704\n",
            "Epoch 443/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6704 - val_loss: 0.6702\n",
            "Epoch 444/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6702 - val_loss: 0.6700\n",
            "Epoch 445/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6700 - val_loss: 0.6698\n",
            "Epoch 446/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6698 - val_loss: 0.6696\n",
            "Epoch 447/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6695 - val_loss: 0.6694\n",
            "Epoch 448/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6696 - val_loss: 0.6692\n",
            "Epoch 449/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6692 - val_loss: 0.6691\n",
            "Epoch 450/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6691 - val_loss: 0.6688\n",
            "Epoch 451/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6687 - val_loss: 0.6686\n",
            "Epoch 452/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6686 - val_loss: 0.6684\n",
            "Epoch 453/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6685 - val_loss: 0.6682\n",
            "Epoch 454/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6681 - val_loss: 0.6680\n",
            "Epoch 455/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6680 - val_loss: 0.6678\n",
            "Epoch 456/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6678 - val_loss: 0.6676\n",
            "Epoch 457/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6677 - val_loss: 0.6674\n",
            "Epoch 458/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6674 - val_loss: 0.6672\n",
            "Epoch 459/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6672 - val_loss: 0.6670\n",
            "Epoch 460/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6670 - val_loss: 0.6668\n",
            "Epoch 461/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6667 - val_loss: 0.6666\n",
            "Epoch 462/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6666 - val_loss: 0.6664\n",
            "Epoch 463/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6663 - val_loss: 0.6662\n",
            "Epoch 464/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6662 - val_loss: 0.6660\n",
            "Epoch 465/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6660 - val_loss: 0.6658\n",
            "Epoch 466/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6657 - val_loss: 0.6656\n",
            "Epoch 467/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6656 - val_loss: 0.6654\n",
            "Epoch 468/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6654 - val_loss: 0.6652\n",
            "Epoch 469/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6653 - val_loss: 0.6650\n",
            "Epoch 470/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6649 - val_loss: 0.6649\n",
            "Epoch 471/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6648 - val_loss: 0.6646\n",
            "Epoch 472/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6645 - val_loss: 0.6644\n",
            "Epoch 473/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6644 - val_loss: 0.6642\n",
            "Epoch 474/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6641 - val_loss: 0.6640\n",
            "Epoch 475/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6639 - val_loss: 0.6637\n",
            "Epoch 476/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6637 - val_loss: 0.6635\n",
            "Epoch 477/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6635 - val_loss: 0.6633\n",
            "Epoch 478/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6633 - val_loss: 0.6631\n",
            "Epoch 479/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6631 - val_loss: 0.6629\n",
            "Epoch 480/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6629 - val_loss: 0.6627\n",
            "Epoch 481/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6627 - val_loss: 0.6625\n",
            "Epoch 482/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6626 - val_loss: 0.6623\n",
            "Epoch 483/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6623 - val_loss: 0.6621\n",
            "Epoch 484/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6621 - val_loss: 0.6619\n",
            "Epoch 485/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6619 - val_loss: 0.6617\n",
            "Epoch 486/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6618 - val_loss: 0.6615\n",
            "Epoch 487/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6617 - val_loss: 0.6613\n",
            "Epoch 488/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6613 - val_loss: 0.6611\n",
            "Epoch 489/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6609 - val_loss: 0.6609\n",
            "Epoch 490/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6609 - val_loss: 0.6607\n",
            "Epoch 491/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6607 - val_loss: 0.6605\n",
            "Epoch 492/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6606 - val_loss: 0.6603\n",
            "Epoch 493/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6604 - val_loss: 0.6602\n",
            "Epoch 494/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6604 - val_loss: 0.6598\n",
            "Epoch 495/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6598 - val_loss: 0.6596\n",
            "Epoch 496/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6596 - val_loss: 0.6594\n",
            "Epoch 497/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6594 - val_loss: 0.6592\n",
            "Epoch 498/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6592 - val_loss: 0.6590\n",
            "Epoch 499/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6590 - val_loss: 0.6588\n",
            "Epoch 500/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.6586\n",
            "Epoch 501/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6586 - val_loss: 0.6584\n",
            "Epoch 502/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6583 - val_loss: 0.6582\n",
            "Epoch 503/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6582 - val_loss: 0.6580\n",
            "Epoch 504/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6580 - val_loss: 0.6578\n",
            "Epoch 505/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6578 - val_loss: 0.6576\n",
            "Epoch 506/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6576 - val_loss: 0.6574\n",
            "Epoch 507/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6573 - val_loss: 0.6572\n",
            "Epoch 508/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6573 - val_loss: 0.6570\n",
            "Epoch 509/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6570 - val_loss: 0.6567\n",
            "Epoch 510/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.6565\n",
            "Epoch 511/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6565 - val_loss: 0.6563\n",
            "Epoch 512/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6563 - val_loss: 0.6561\n",
            "Epoch 513/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6561 - val_loss: 0.6559\n",
            "Epoch 514/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6559 - val_loss: 0.6557\n",
            "Epoch 515/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6555\n",
            "Epoch 516/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6557 - val_loss: 0.6553\n",
            "Epoch 517/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6554 - val_loss: 0.6551\n",
            "Epoch 518/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6551 - val_loss: 0.6549\n",
            "Epoch 519/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6552 - val_loss: 0.6547\n",
            "Epoch 520/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6546 - val_loss: 0.6545\n",
            "Epoch 521/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6545 - val_loss: 0.6543\n",
            "Epoch 522/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6543 - val_loss: 0.6541\n",
            "Epoch 523/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6540 - val_loss: 0.6539\n",
            "Epoch 524/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6540 - val_loss: 0.6537\n",
            "Epoch 525/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6536 - val_loss: 0.6534\n",
            "Epoch 526/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6535 - val_loss: 0.6533\n",
            "Epoch 527/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6533 - val_loss: 0.6531\n",
            "Epoch 528/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6530 - val_loss: 0.6528\n",
            "Epoch 529/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6528 - val_loss: 0.6526\n",
            "Epoch 530/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6526 - val_loss: 0.6524\n",
            "Epoch 531/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6525 - val_loss: 0.6522\n",
            "Epoch 532/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6523 - val_loss: 0.6521\n",
            "Epoch 533/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6521 - val_loss: 0.6518\n",
            "Epoch 534/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6518 - val_loss: 0.6516\n",
            "Epoch 535/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6516 - val_loss: 0.6514\n",
            "Epoch 536/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6514 - val_loss: 0.6512\n",
            "Epoch 537/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6512 - val_loss: 0.6510\n",
            "Epoch 538/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6508\n",
            "Epoch 539/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6510 - val_loss: 0.6507\n",
            "Epoch 540/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6506 - val_loss: 0.6505\n",
            "Epoch 541/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6504 - val_loss: 0.6502\n",
            "Epoch 542/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6503 - val_loss: 0.6500\n",
            "Epoch 543/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6502 - val_loss: 0.6499\n",
            "Epoch 544/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6499 - val_loss: 0.6496\n",
            "Epoch 545/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6498 - val_loss: 0.6494\n",
            "Epoch 546/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6494 - val_loss: 0.6493\n",
            "Epoch 547/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6492 - val_loss: 0.6490\n",
            "Epoch 548/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6490 - val_loss: 0.6488\n",
            "Epoch 549/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6488 - val_loss: 0.6486\n",
            "Epoch 550/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6490 - val_loss: 0.6484\n",
            "Epoch 551/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6488 - val_loss: 0.6482\n",
            "Epoch 552/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.6480\n",
            "Epoch 553/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.6478\n",
            "Epoch 554/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6479 - val_loss: 0.6476\n",
            "Epoch 555/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6476 - val_loss: 0.6474\n",
            "Epoch 556/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6475 - val_loss: 0.6472\n",
            "Epoch 557/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6472 - val_loss: 0.6470\n",
            "Epoch 558/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6470 - val_loss: 0.6468\n",
            "Epoch 559/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6468 - val_loss: 0.6466\n",
            "Epoch 560/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6467 - val_loss: 0.6464\n",
            "Epoch 561/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6464 - val_loss: 0.6462\n",
            "Epoch 562/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6463 - val_loss: 0.6460\n",
            "Epoch 563/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6461 - val_loss: 0.6458\n",
            "Epoch 564/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6463 - val_loss: 0.6456\n",
            "Epoch 565/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6460 - val_loss: 0.6454\n",
            "Epoch 566/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6460 - val_loss: 0.6452\n",
            "Epoch 567/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6455 - val_loss: 0.6451\n",
            "Epoch 568/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6451 - val_loss: 0.6449\n",
            "Epoch 569/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6450 - val_loss: 0.6447\n",
            "Epoch 570/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6446 - val_loss: 0.6445\n",
            "Epoch 571/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6445 - val_loss: 0.6443\n",
            "Epoch 572/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6443 - val_loss: 0.6441\n",
            "Epoch 573/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6441 - val_loss: 0.6439\n",
            "Epoch 574/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6438 - val_loss: 0.6437\n",
            "Epoch 575/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6440 - val_loss: 0.6436\n",
            "Epoch 576/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6436 - val_loss: 0.6433\n",
            "Epoch 577/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6435 - val_loss: 0.6431\n",
            "Epoch 578/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6432 - val_loss: 0.6429\n",
            "Epoch 579/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6430 - val_loss: 0.6428\n",
            "Epoch 580/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6428 - val_loss: 0.6426\n",
            "Epoch 581/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6430 - val_loss: 0.6425\n",
            "Epoch 582/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6425 - val_loss: 0.6422\n",
            "Epoch 583/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6423 - val_loss: 0.6421\n",
            "Epoch 584/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6422 - val_loss: 0.6418\n",
            "Epoch 585/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6419 - val_loss: 0.6416\n",
            "Epoch 586/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6418 - val_loss: 0.6415\n",
            "Epoch 587/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6415 - val_loss: 0.6413\n",
            "Epoch 588/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6417 - val_loss: 0.6412\n",
            "Epoch 589/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6416 - val_loss: 0.6409\n",
            "Epoch 590/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6410 - val_loss: 0.6407\n",
            "Epoch 591/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6408 - val_loss: 0.6405\n",
            "Epoch 592/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6407 - val_loss: 0.6404\n",
            "Epoch 593/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6404 - val_loss: 0.6402\n",
            "Epoch 594/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6402 - val_loss: 0.6400\n",
            "Epoch 595/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6400 - val_loss: 0.6399\n",
            "Epoch 596/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6398 - val_loss: 0.6396\n",
            "Epoch 597/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6397 - val_loss: 0.6394\n",
            "Epoch 598/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6394 - val_loss: 0.6393\n",
            "Epoch 599/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6395 - val_loss: 0.6392\n",
            "Epoch 600/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6391 - val_loss: 0.6389\n",
            "Epoch 601/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6391 - val_loss: 0.6388\n",
            "Epoch 602/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6387 - val_loss: 0.6386\n",
            "Epoch 603/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6388 - val_loss: 0.6384\n",
            "Epoch 604/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6385 - val_loss: 0.6382\n",
            "Epoch 605/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6384 - val_loss: 0.6382\n",
            "Epoch 606/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6382 - val_loss: 0.6379\n",
            "Epoch 607/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6378 - val_loss: 0.6377\n",
            "Epoch 608/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6380 - val_loss: 0.6375\n",
            "Epoch 609/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6382 - val_loss: 0.6375\n",
            "Epoch 610/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6373 - val_loss: 0.6372\n",
            "Epoch 611/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6372 - val_loss: 0.6370\n",
            "Epoch 612/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6370 - val_loss: 0.6368\n",
            "Epoch 613/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6371 - val_loss: 0.6367\n",
            "Epoch 614/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6374 - val_loss: 0.6374\n",
            "Epoch 615/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6372 - val_loss: 0.6366\n",
            "Epoch 616/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6365 - val_loss: 0.6362\n",
            "Epoch 617/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6362 - val_loss: 0.6360\n",
            "Epoch 618/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6361 - val_loss: 0.6359\n",
            "Epoch 619/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6360 - val_loss: 0.6357\n",
            "Epoch 620/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6357 - val_loss: 0.6356\n",
            "Epoch 621/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6355 - val_loss: 0.6354\n",
            "Epoch 622/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6356 - val_loss: 0.6353\n",
            "Epoch 623/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6355 - val_loss: 0.6350\n",
            "Epoch 624/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6353 - val_loss: 0.6350\n",
            "Epoch 625/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6352 - val_loss: 0.6351\n",
            "Epoch 626/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6349 - val_loss: 0.6347\n",
            "Epoch 627/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6348 - val_loss: 0.6344\n",
            "Epoch 628/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6346 - val_loss: 0.6343\n",
            "Epoch 629/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6345 - val_loss: 0.6340\n",
            "Epoch 630/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.6341\n",
            "Epoch 631/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6340 - val_loss: 0.6338\n",
            "Epoch 632/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6339 - val_loss: 0.6336\n",
            "Epoch 633/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6337 - val_loss: 0.6335\n",
            "Epoch 634/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6334 - val_loss: 0.6333\n",
            "Epoch 635/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6334 - val_loss: 0.6332\n",
            "Epoch 636/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6341 - val_loss: 0.6333\n",
            "Epoch 637/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6335 - val_loss: 0.6328\n",
            "Epoch 638/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6329 - val_loss: 0.6327\n",
            "Epoch 639/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6327 - val_loss: 0.6325\n",
            "Epoch 640/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6327 - val_loss: 0.6323\n",
            "Epoch 641/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6325 - val_loss: 0.6322\n",
            "Epoch 642/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6324 - val_loss: 0.6321\n",
            "Epoch 643/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6322 - val_loss: 0.6319\n",
            "Epoch 644/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6320 - val_loss: 0.6317\n",
            "Epoch 645/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6321 - val_loss: 0.6316\n",
            "Epoch 646/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.6317\n",
            "Epoch 647/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6318 - val_loss: 0.6326\n",
            "Epoch 648/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6322 - val_loss: 0.6320\n",
            "Epoch 649/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6313 - val_loss: 0.6315\n",
            "Epoch 650/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6311 - val_loss: 0.6310\n",
            "Epoch 651/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6311 - val_loss: 0.6308\n",
            "Epoch 652/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6311 - val_loss: 0.6306\n",
            "Epoch 653/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6307 - val_loss: 0.6305\n",
            "Epoch 654/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6309 - val_loss: 0.6307\n",
            "Epoch 655/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6313 - val_loss: 0.6306\n",
            "Epoch 656/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6321 - val_loss: 0.6309\n",
            "Epoch 657/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6305 - val_loss: 0.6298\n",
            "Epoch 658/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6301 - val_loss: 0.6297\n",
            "Epoch 659/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6298 - val_loss: 0.6297\n",
            "Epoch 660/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6295\n",
            "Epoch 661/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6299 - val_loss: 0.6302\n",
            "Epoch 662/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6298 - val_loss: 0.6299\n",
            "Epoch 663/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6295 - val_loss: 0.6301\n",
            "Epoch 664/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6293 - val_loss: 0.6290\n",
            "Epoch 665/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.6288\n",
            "Epoch 666/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6295 - val_loss: 0.6287\n",
            "Epoch 667/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6289 - val_loss: 0.6285\n",
            "Epoch 668/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6288 - val_loss: 0.6287\n",
            "Epoch 669/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6292 - val_loss: 0.6283\n",
            "Epoch 670/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6285 - val_loss: 0.6285\n",
            "Epoch 671/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6288 - val_loss: 0.6293\n",
            "Epoch 672/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6287 - val_loss: 0.6279\n",
            "Epoch 673/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6280 - val_loss: 0.6278\n",
            "Epoch 674/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6279 - val_loss: 0.6276\n",
            "Epoch 675/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6283 - val_loss: 0.6284\n",
            "Epoch 676/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6284 - val_loss: 0.6277\n",
            "Epoch 677/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6282 - val_loss: 0.6278\n",
            "Epoch 678/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6281 - val_loss: 0.6277\n",
            "Epoch 679/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6278 - val_loss: 0.6271\n",
            "Epoch 680/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6271 - val_loss: 0.6269\n",
            "Epoch 681/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.6268\n",
            "Epoch 682/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6273 - val_loss: 0.6269\n",
            "Epoch 683/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6271 - val_loss: 0.6268\n",
            "Epoch 684/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6266 - val_loss: 0.6266\n",
            "Epoch 685/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.6267\n",
            "Epoch 686/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6268 - val_loss: 0.6263\n",
            "Epoch 687/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6269 - val_loss: 0.6269\n",
            "Epoch 688/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6265 - val_loss: 0.6261\n",
            "Epoch 689/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6263 - val_loss: 0.6262\n",
            "Epoch 690/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6264 - val_loss: 0.6267\n",
            "Epoch 691/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6258 - val_loss: 0.6261\n",
            "Epoch 692/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6263 - val_loss: 0.6259\n",
            "Epoch 693/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6260 - val_loss: 0.6257\n",
            "Epoch 694/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6257 - val_loss: 0.6255\n",
            "Epoch 695/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6254 - val_loss: 0.6254\n",
            "Epoch 696/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6254 - val_loss: 0.6255\n",
            "Epoch 697/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6254 - val_loss: 0.6252\n",
            "Epoch 698/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.6249\n",
            "Epoch 699/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6257 - val_loss: 0.6248\n",
            "Epoch 700/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6253 - val_loss: 0.6250\n",
            "Epoch 701/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6250 - val_loss: 0.6253\n",
            "Epoch 702/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.6249\n",
            "Epoch 703/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6248 - val_loss: 0.6245\n",
            "Epoch 704/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6246 - val_loss: 0.6244\n",
            "Epoch 705/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6248 - val_loss: 0.6242\n",
            "Epoch 706/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6245 - val_loss: 0.6243\n",
            "Epoch 707/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6256 - val_loss: 0.6241\n",
            "Epoch 708/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.6240\n",
            "Epoch 709/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6243 - val_loss: 0.6242\n",
            "Epoch 710/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6241 - val_loss: 0.6238\n",
            "Epoch 711/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6243 - val_loss: 0.6239\n",
            "Epoch 712/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6243 - val_loss: 0.6236\n",
            "Epoch 713/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 0.6236\n",
            "Epoch 714/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6236 - val_loss: 0.6238\n",
            "Epoch 715/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6239 - val_loss: 0.6235\n",
            "Epoch 716/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6241 - val_loss: 0.6237\n",
            "Epoch 717/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6240 - val_loss: 0.6232\n",
            "Epoch 718/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6234 - val_loss: 0.6232\n",
            "Epoch 719/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6235 - val_loss: 0.6230\n",
            "Epoch 720/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6232 - val_loss: 0.6229\n",
            "Epoch 721/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.6229\n",
            "Epoch 722/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6233 - val_loss: 0.6227\n",
            "Epoch 723/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6226\n",
            "Epoch 724/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6225\n",
            "Epoch 725/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6228 - val_loss: 0.6225\n",
            "Epoch 726/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6231 - val_loss: 0.6225\n",
            "Epoch 727/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6225 - val_loss: 0.6225\n",
            "Epoch 728/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6222\n",
            "Epoch 729/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6223\n",
            "Epoch 730/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6225 - val_loss: 0.6226\n",
            "Epoch 731/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6226 - val_loss: 0.6226\n",
            "Epoch 732/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6224 - val_loss: 0.6228\n",
            "Epoch 733/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6227 - val_loss: 0.6218\n",
            "Epoch 734/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6223 - val_loss: 0.6222\n",
            "Epoch 735/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6221 - val_loss: 0.6218\n",
            "Epoch 736/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6218 - val_loss: 0.6217\n",
            "Epoch 737/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6221 - val_loss: 0.6216\n",
            "Epoch 738/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6218 - val_loss: 0.6216\n",
            "Epoch 739/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6219 - val_loss: 0.6215\n",
            "Epoch 740/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6221 - val_loss: 0.6222\n",
            "Epoch 741/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6218 - val_loss: 0.6213\n",
            "Epoch 742/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6223 - val_loss: 0.6213\n",
            "Epoch 743/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6215 - val_loss: 0.6215\n",
            "Epoch 744/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6212 - val_loss: 0.6217\n",
            "Epoch 745/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6213 - val_loss: 0.6217\n",
            "Epoch 746/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6215 - val_loss: 0.6210\n",
            "Epoch 747/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6211 - val_loss: 0.6212\n",
            "Epoch 748/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6209 - val_loss: 0.6208\n",
            "Epoch 749/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6209 - val_loss: 0.6208\n",
            "Epoch 750/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6212 - val_loss: 0.6206\n",
            "Epoch 751/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6206\n",
            "Epoch 752/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6207\n",
            "Epoch 753/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6207 - val_loss: 0.6209\n",
            "Epoch 754/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6204\n",
            "Epoch 755/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6206 - val_loss: 0.6205\n",
            "Epoch 756/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6208 - val_loss: 0.6203\n",
            "Epoch 757/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6210 - val_loss: 0.6214\n",
            "Epoch 758/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6209 - val_loss: 0.6203\n",
            "Epoch 759/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6205 - val_loss: 0.6201\n",
            "Epoch 760/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6203 - val_loss: 0.6202\n",
            "Epoch 761/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6200 - val_loss: 0.6200\n",
            "Epoch 762/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6201 - val_loss: 0.6199\n",
            "Epoch 763/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6201 - val_loss: 0.6199\n",
            "Epoch 764/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6200 - val_loss: 0.6199\n",
            "Epoch 765/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6197\n",
            "Epoch 766/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6197\n",
            "Epoch 767/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6202 - val_loss: 0.6199\n",
            "Epoch 768/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6200 - val_loss: 0.6196\n",
            "Epoch 769/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6197 - val_loss: 0.6206\n",
            "Epoch 770/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6202 - val_loss: 0.6196\n",
            "Epoch 771/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6198 - val_loss: 0.6197\n",
            "Epoch 772/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6204 - val_loss: 0.6199\n",
            "Epoch 773/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6198 - val_loss: 0.6194\n",
            "Epoch 774/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6196 - val_loss: 0.6193\n",
            "Epoch 775/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6197 - val_loss: 0.6206\n",
            "Epoch 776/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6207 - val_loss: 0.6199\n",
            "Epoch 777/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6195 - val_loss: 0.6191\n",
            "Epoch 778/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6193 - val_loss: 0.6192\n",
            "Epoch 779/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6193 - val_loss: 0.6191\n",
            "Epoch 780/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6193 - val_loss: 0.6189\n",
            "Epoch 781/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6193 - val_loss: 0.6196\n",
            "Epoch 782/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6194 - val_loss: 0.6189\n",
            "Epoch 783/1000\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6196 - val_loss: 0.6189\n",
            "Epoch 784/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6191 - val_loss: 0.6188\n",
            "Epoch 785/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6190 - val_loss: 0.6187\n",
            "Epoch 786/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6189 - val_loss: 0.6190\n",
            "Epoch 787/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6191 - val_loss: 0.6187\n",
            "Epoch 788/1000\n",
            "15/15 [==============================] - 0s 5ms/step - loss: 0.6188 - val_loss: 0.6188\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGoO8jeminsp",
        "outputId": "d9cbbfc1-6f8c-497b-a859-92dc01f1b76f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(15,7))\n",
        "\n",
        "# 학습 정확성 값과 검증 정확성 값을 플롯팅 합니다. \n",
        "\n",
        "# 학습 손실 값과 검증 손실 값을 플롯팅 합니다.\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "#plt.ylim(0,1.4)\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfCgOjaijKRM",
        "outputId": "091bbbd1-8160-4b5c-ec24-c6325182b9d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 6. 모델 평가하기\n",
        "loss_and_metrics = model.evaluate(X_test,  Y_test, batch_size=1000 ,verbose=2)\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 - 0s - loss: 0.6233\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNa0Uq1-mWTp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}